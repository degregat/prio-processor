# Prio-Processor architecture

## python-libprio

`python-libprio` is a Python3 extension module that wraps the Prio routines. It
implements a SWIG interface for building Python wrappers.

The wrapper generated by the SWIG interface file mirrors the structure of code
in "mprio.h".

```python
from prio.libprio import *

data_in = ...   # <class 'bytes'>
server = ...    # <class 'PyCapsule'>

verifier = PrioVerifier_new(server)
packet = PrioPacketVerify1_new()

PrioVerifier_set_data(verifier, data)
PrioPacketVerify1_set_data(packet, verifier)

data_out = PrioPacketVerify1_write(packet)
```

The `prio` module provides an higher-level API that handles initialization,
reference-counting and serialization.

```python
from prio.prio import *
import pickle

data_in = ...   # <class 'bytes'>
server = ...    # <class 'Server'>

with Prio() as p:
    verifier = p.Verifier(server, data_in)
    data_out = pickle.dumps(verifier.create_verify1())
```

These libraries are used to build up a series of examples that include
asynchronous I/O, multi-processing, and container orchestration.

## The `prio` cli tool

The `prio` command-line interface (CLI) encapsulates data processing into a
series of sub-commands. Each command is self-contained and comes with a help
page.

```bash
$ prio --help

Usage: prio [OPTIONS] COMMAND [ARGS]...

  Command line utility for prio.

Options:
  --help  Show this message and exit.

Commands:
  aggregate      Generate an aggregate share from a batch of verified SNIPs
  encode-shares  Encode JSON bit-vector into base64-encoded shares.
  keygen         Generate a curve25519 key pair as json.
  publish        Generate a final aggregate and remap data to a content...
  shared-seed    Generate a shared server secret in base64.
  verify1        Decode a batch of shares
  verify2        Verify a batch of SNIPs
```

The CLI uses `click` for option parsing and command structure. The `jq` tool is
the primary tool to diagnose data.

```sh
# Create a new JSON key and store it to a file.
$ prio keygen > keyfile

# Create 
$ jq 'keys'  keyfile
[
  "private_key",
  "public_key"
]

$ jq -r '.public_key' keyfile
"AF90AA5CE9B8D34D1777770C64F2CB44739EF625C61E263FB308DA85BE4D2016"
```

The `prio` commands accept arguments either the environment or the command-line.
This example of creating a shared proof utilizes `jq` and `prio` in shell.

```sh
#!/bin/sh

export PUBLIC_KEY_HEX_INTERNAL=$(prio keygen | jq -r '.public_key')
export PUBLIC_KEY_HEX_EXTERNAL=$(prio keygen | jq -r '.public_key')

cd /tmp
mkdir -p data/a data/b

# an array with ten `1`s
n_data=10
python3 -c "print([1]*${n_data})" > data/part-0.json

prio encode-shares \
    --n-data ${n_data} \
    --batch-id "testing.test-0" \
    --input /tmp/data/part-0.json \
    --output-A /tmp/data/a \
    --output-B /tmp/data/b
    # --public-key-hex-internal is read from the environment
    # --public-key-hex-external is read from the environment

cd -
```

Data looks like this:

```json
{
  "id": "7dc16f11-87bf-4631-944a-4b63a8646502",
  "payload": "BvSRhK0vxVp+/6plOy+lVw9h1soYKA0N/QB130p7qV2CXai9tkNjqZQAihhm..."
}
```

## Parallel processing

The `prio-processor process` script uses [GNU
Parallel](https://www.gnu.org/software/parallel/) to maximize resource
utilization. The `prio-processor staging` command will transform data from the
"prio" ping into `(id, packet)` records, range partitioned by their batch
identifiers.

```bash
function list_partitions() {
  # return a list of paths to available partitions
  ...
}

function verify1() {
  # ensure options have been set for `prio verify1`
  local input=$1
  prio verify1 ...
}

# Re-export any necessary environment variables.
...
# Export the function so a separate GNU Parallel process can use it.
export -f verify1

# Process all partitions in parallel using a semaphore equal to the core count.
parallel verify1 :: $(list_partitions)
```